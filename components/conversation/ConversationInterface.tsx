'use client'

import { useState, useRef, useEffect } from 'react'
import { Send, Mic, Volume2, StopCircle } from 'lucide-react'

interface Message {
  role: 'user' | 'assistant'
  content: string
  timestamp: Date
}

import { storage, ConversationHistory } from '@/lib/storage'

interface Props {
  scenario?: string
  initialHistory?: ConversationHistory | null
  onHistoryChange?: () => void
}

export default function ConversationInterface({ 
  scenario,
  initialHistory,
  onHistoryChange
}: Props) {
  const [messages, setMessages] = useState<Message[]>([])
  const [input, setInput] = useState('')
  const [isRecording, setIsRecording] = useState(false)
  const [isLoading, setIsLoading] = useState(false)
  const [conversationId, setConversationId] = useState<string>('')
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const audioContextRef = useRef<AudioContext | null>(null)
  const audioSourceRef = useRef<AudioBufferSourceNode | null>(null)

  // ëŒ€í™” ë‚´ì—­ ë¶ˆëŸ¬ì˜¤ê¸°
  useEffect(() => {
    if (scenario && !initialHistory) {
      loadLatestConversation(scenario)
    }
  }, [scenario])

  // ì´ˆê¸° ëŒ€í™” ë‚´ì—­ ë¡œë“œ
  useEffect(() => {
    if (initialHistory) {
      setConversationId(initialHistory.id)
      setMessages(
        initialHistory.messages.map(m => ({
          role: m.role as 'user' | 'assistant',
          content: m.content,
          timestamp: new Date(initialHistory.timestamp)
        }))
      )
    }
  }, [initialHistory])

  // AudioContext ì´ˆê¸°í™”
  useEffect(() => {
    audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)()
    return () => {
      // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
      audioContextRef.current?.close()
      stopRecording()
      // ëŒ€í™” ë‚´ì—­ ì €ì¥
      if (messages.length > 0 && scenario) {
        saveConversation()
      }
    }
  }, [])

  // ìµœê·¼ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
  const loadLatestConversation = (currentScenario: string) => {
    const history = storage.getConversationHistory()
    const latestConversation = history.find(h => h.scenario === currentScenario)
    
    if (latestConversation) {
      setConversationId(latestConversation.id)
      setMessages(
        latestConversation.messages.map(m => ({
          role: m.role as 'user' | 'assistant',
          content: m.content,
          timestamp: new Date(latestConversation.timestamp)
        }))
      )
    } else {
      // ìƒˆ ëŒ€í™” ì‹œì‘
      setConversationId(generateId())
      setMessages([])
    }
  }

  // ëŒ€í™” ì €ì¥
  const saveConversation = () => {
    if (!scenario || messages.length === 0) return

    const conversation: ConversationHistory = {
      id: conversationId || generateId(),
      scenario,
      messages: messages.map(m => ({ role: m.role, content: m.content })),
      timestamp: new Date()
    }

    storage.addConversationHistory(conversation)
  }

  // ID ìƒì„± í—¬í¼
  const generateId = () => {
    return `conv-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
  }

  const handleSend = async () => {
    if (!input.trim() || !scenario) return

    const userMessage: Message = {
      role: 'user',
      content: input,
      timestamp: new Date(),
    }

    const updatedMessagesWithUser = [...messages, userMessage]; // åŒ…å«ç”¨æˆ·æ¶ˆæ¯
    setMessages(updatedMessagesWithUser);
    setInput('')
    setIsLoading(true)

    try {
      const response = await fetch('/api/conversation', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          scenario,
          message: input,
          history: updatedMessagesWithUser.map(m => ({ role: m.role, content: m.content })), // API history should include the current message
        }),
      })

      if (!response.ok) {
        // å¦‚æœå“åº”ä¸æ˜¯ OKï¼Œè¯»å–æ–‡æœ¬å†…å®¹ä»¥è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
        const errorText = await response.text();
        console.error('API å“åº”é”™è¯¯ (é JSON):', errorText);
        // å°è¯•è§£æ JSONï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é€šç”¨é”™è¯¯æ¶ˆæ¯
        try {
          const errorData = JSON.parse(errorText);
          throw new Error(errorData.error || `æœåŠ¡å™¨é”™è¯¯: ${response.status}`);
        } catch {
          throw new Error(`æœåŠ¡å™¨è¿”å›é JSON é”™è¯¯: ${response.status} - ${errorText.substring(0, 100)}...`);
        }
      }
      const data = await response.json();

      const aiMessage: Message = {
        role: 'assistant',
        content: data.response,
        timestamp: new Date(),
      }
      
      // å°†ç”¨æˆ·æ¶ˆæ¯å’Œ AI æ¶ˆæ¯ä¸€èµ·æ›´æ–°åˆ°çŠ¶æ€ä¸­
      setMessages(prev => [...prev, aiMessage]);

      // ëŒ€í™” ìë™ ì €ì¥
      const conversation: ConversationHistory = {
        id: conversationId || generateId(),
        scenario,
        messages: [...updatedMessagesWithUser, aiMessage].map(m => ({ role: m.role, content: m.content })), // ä¿å­˜æ‰€æœ‰æ¶ˆæ¯
        timestamp: new Date()
      }
      storage.addConversationHistory(conversation)
      
      // ëŒ€í™” ë‚´ì—­ì´ ë³€ê²½ë˜ì—ˆìŒì„ ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ì— ì•Œë¦¼
      onHistoryChange?.()
      if (!conversationId) setConversationId(conversation.id);

    } catch (error) {
      console.error('Error sending message:', error);
      if (error instanceof Error) {
        // ä½¿ç”¨æ›´å‹å¥½çš„é”™è¯¯æç¤º
        const friendlyMessage = error.message.includes('404') 
          ? 'ëŒ€í™” APIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (404 Not Found)' 
          : 'ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
        alert(friendlyMessage);
      } else {
        alert('ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      }
    } finally {
      setIsLoading(false)
    }
  }

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const mediaRecorder = new MediaRecorder(stream)
      mediaRecorderRef.current = mediaRecorder
      audioChunksRef.current = []

      mediaRecorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data)
      }

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        await handleAudioSubmission(audioBlob)
        stream.getTracks().forEach(track => track.stop())
      }

      mediaRecorder.start()
      setIsRecording(true)
    } catch (error) {
      console.error('Error starting recording:', error)
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.')
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
    }
  }

  const handleVoiceInput = () => {
    if (isRecording) {
      stopRecording()
    } else {
      startRecording()
    }
  }

  const handleAudioSubmission = async (audioBlob: Blob) => {
    setIsLoading(true)

    try {
      // ç¡®ä¿éŸ³é¢‘æ–‡ä»¶ä¸ä¸ºç©ºä¸”å¤§å°åˆé€‚
      if (audioBlob.size === 0) {
        throw new Error('ë…¹ìŒëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.')
      }
      if (audioBlob.size > 25 * 1024 * 1024) {
        throw new Error('ìŒì„± íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 25MB ì´í•˜ë¡œ ë…¹ìŒí•´ì£¼ì„¸ìš”.')
      }

      const formData = new FormData()
      // æ·»åŠ éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨åˆé€‚çš„æ–‡ä»¶åå’ŒMIMEç±»å‹
      formData.append('audio', new File([audioBlob], 'recording.webm', { type: 'audio/webm' }))
      formData.append('text', messages[messages.length - 1]?.content || '')

      const response = await fetch('/api/speech', {
        method: 'POST',
        body: formData,
      })

      if (!response.ok) {
        const errorText = await response.text();
        console.error('API å“åº”é”™è¯¯ (é JSON):', errorText);
        try {
          const errorData = JSON.parse(errorText);
          throw new Error(errorData.error || `æœåŠ¡å™¨é”™è¯¯: ${response.status}`);
        } catch {
          throw new Error(`æœåŠ¡å™¨è¿”å›é JSON é”™è¯¯: ${response.status} - ${errorText.substring(0, 100)}...`);
        }
      }
      const data = await response.json();

      // ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ í•„ë“œì— ì„¤ì •
      setInput(data.transcription)
      
      // ë°œìŒ í”¼ë“œë°±ì´ ìˆìœ¼ë©´ í‘œì‹œ
      if (data.feedback) {
        const feedbackMessage: Message = {
          role: 'assistant',
          content: `ğŸ¯ ë°œìŒ í”¼ë“œë°±: ${data.feedback} (ì ìˆ˜: ${data.score}/100)`,
          timestamp: new Date(),
        }
        setMessages(prev => [...prev, feedbackMessage])
      }
    } catch (error) {
      console.error('Error submitting audio:', error);
      if (error instanceof Error && error.message.includes('ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤')) {
        // å¦‚æœé”™è¯¯æ˜¯â€œæœªèƒ½å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬â€ï¼Œåˆ™æ˜¾ç¤ºâ€œè¯·é‡æ–°è¾“å…¥â€
        alert('ì¸ì‹ëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”. (è¯·é‡æ–°è¾“å…¥)');
      } else {
        alert('ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      }
    } finally {
      setIsLoading(false)
    }
  }

  const playAudio = async (text: string) => {
    try {
      // ê¸°ì¡´ ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì •ì§€
      audioSourceRef.current?.stop()
      
      // ìƒˆ AudioContext ìƒì„± ë˜ëŠ” ì¬ê°œ
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)()
      }
      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume()
      }

      // TODO: TTS API í˜¸ì¶œí•˜ì—¬ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
      const response = await fetch('https://api.example.com/tts', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text }),
      })

      const arrayBuffer = await response.arrayBuffer()
      const audioBuffer = await audioContextRef.current.decodeAudioData(arrayBuffer)
      
      const source = audioContextRef.current.createBufferSource()
      source.buffer = audioBuffer
      source.connect(audioContextRef.current.destination)
      audioSourceRef.current = source
      
      source.start(0)
    } catch (error) {
      console.error('Error playing audio:', error)
      alert('ìŒì„± ì¬ìƒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
    }
  }

  return (
    <div className="bg-white dark:bg-gray-800 rounded-2xl shadow-lg p-6 flex flex-col h-[600px]">
      {/* Messages */}
      <div className="flex-1 overflow-y-auto mb-4 space-y-4">
        {messages.length === 0 ? (
          <div className="text-center text-gray-500 dark:text-gray-400 py-12">
            <p>ìƒí™©ì„ ì„ íƒí•˜ê³  ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”</p>
            <p className="text-sm mt-2">í…ìŠ¤íŠ¸ë‚˜ ìŒì„±ìœ¼ë¡œ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</p>
          </div>
        ) : (
          messages.map((message, index) => (
            <div
              key={index}
              className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}
            >
              <div
                className={`max-w-[80%] rounded-lg p-3 ${
                  message.role === 'user'
                    ? 'bg-blue-600 text-white'
                    : 'bg-gray-100 dark:bg-gray-700 text-gray-900 dark:text-white'
                }`}
              >
                <div className="flex justify-between items-start mb-1">
                  <p>{message.content}</p>
                  {message.role === 'assistant' && (
                    <button
                      onClick={() => playAudio(message.content)}
                      className="ml-2 p-1 text-gray-600 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white"
                    >
                      <Volume2 size={16} />
                    </button>
                  )}
                </div>
                <p className={`text-xs mt-1 ${
                  message.role === 'user' ? 'text-blue-100' : 'text-gray-500 dark:text-gray-400'
                }`}>
                  {message.timestamp.toLocaleTimeString()}
                </p>
              </div>
            </div>
          ))
        )}
      </div>

      {/* Input */}
      <div className="flex items-center space-x-2">
        <button
          onClick={handleVoiceInput}
          className={`p-3 rounded-lg transition-colors ${
            isRecording
              ? 'bg-red-500 text-white animate-pulse'
              : 'bg-gray-100 dark:bg-gray-700 text-gray-700 dark:text-gray-300 hover:bg-gray-200 dark:hover:bg-gray-600'
          }`}
          title={isRecording ? 'ë…¹ìŒ ì¤‘ì§€' : 'ìŒì„±ìœ¼ë¡œ ë§í•˜ê¸°'}
        >
          {isRecording ? <StopCircle size={20} /> : <Mic size={20} />}
        </button>
        
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && handleSend()}
          placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
          disabled={isRecording}
          className="flex-1 px-4 py-3 border border-gray-300 dark:border-gray-600 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent dark:bg-gray-700 dark:text-white disabled:opacity-50 disabled:cursor-not-allowed"
        />
        
        <button
          onClick={handleSend}
          disabled={!input.trim() || isRecording || isLoading}
          className="bg-gradient-to-r from-blue-600 to-purple-600 text-white p-3 rounded-lg hover:shadow-lg transition-all disabled:opacity-50 disabled:cursor-not-allowed"
        >
          <Send size={20} className={isLoading ? 'animate-pulse' : ''} />
        </button>
      </div>
    </div>
  )
}
